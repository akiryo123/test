# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Phase-1 : Base Parquet ä½œæˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ (JRA06 Ver.)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
import polars as pl
import unicodedata as _ud
import json, re, time, shutil, os
import math
import csv
from pathlib import Path
# çµ±è¨ˆé‡è¨ˆç®—ã®ãŸã‚ã«å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (Polars ã«å«ã¾ã‚Œãªã„çµ±è¨ˆé‡ãªã©)
# from scipy.stats import skew, kurtosis # Polars ã§è¨ˆç®—ã§ãã‚‹ãŸã‚ä¸è¦

# â”€â”€ å…¥å‡ºåŠ›ãƒ‘ã‚¹  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
DATA_CSV = "/content/drive/My Drive/Colab/gpt/JRA06/JRA_AI_GPT06_2016.csv"
BASE_PARQUET = "/content/drive/My Drive/Colab/gpt/JRA06/JRA_base_data_2016.parquet"
J2E_JSON = "/content/drive/My Drive/Colab/gpt/JRA06/artifacts_place/j2e.json"
AUDIT_META_CSV = "/content/drive/My Drive/Colab/gpt/JRA06/artifacts_phase1/audit_meta.csv"


# â”€â”€ æ—¥æœ¬èªâ†’è‹±èªãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸  â”€â”€
# ==========================================================
# 1) æ—¥æœ¬èª â†’ è‹±èª å¤‰æ›è¾æ›¸ (ç¨®é¡åˆ¥æ•´ç† + å…¨é …ç›®ç¶²ç¾…ç‰ˆ)
# ==========================================================
j2e = {
    # --- ãƒ¬ãƒ¼ã‚¹åŸºæœ¬æƒ…å ± (Race Basic Info) ---
    "ç«¶èµ°ã‚³ãƒ¼ãƒ‰": "race_code",
    "å¹´æœˆæ—¥": "date",
    "æœˆåº¦": "month", # æœˆåº¦ (e.g., 1-12)
    "ç«¶èµ°ç•ªå·": "race_number", # ãƒ¬ãƒ¼ã‚¹ç•ªå· (e.g., 1-12)
    "å ´ã‚³ãƒ¼ãƒ‰": "venue_code", # ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
    "ãƒˆãƒ©ãƒƒã‚¯ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰": "track_surface_code", # é¦¬å ´ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰ (èŠ/ãƒ€ãƒ¼ãƒˆ/éšœå®³)
    "ãƒˆãƒ©ãƒƒã‚¯ã‚³ãƒ¼ãƒ‰": "track_code", # ã‚³ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ (å†…/å¤–/ç›´ç·šãªã©)
    "è·é›¢": "distance", # è·é›¢ (m)
    "ç™ºèµ°æ™‚åˆ»": "start_time", # ç™ºèµ°æ™‚åˆ»
    "å›æ¬¡": "meeting_order", # é–‹å‚¬å›æ¬¡ (ä¾‹: ç¬¬1å›)
    "æ—¥æ¬¡": "day_order", # é–‹å‚¬æ—¥æ¬¡ (ä¾‹: 1æ—¥)
    "ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰": "grade_code", # ãƒ¬ãƒ¼ã‚¹ã‚°ãƒ¬ãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ (G1, G2, etc.)
    "ç«¶èµ°ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰": "race_type_code", # ç«¶èµ°ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰ (å¹³åœ°/éšœå®³ãªã©)
    "ç«¶èµ°æ¡ä»¶ã‚³ãƒ¼ãƒ‰": "race_condition_code", # ç«¶èµ°æ¡ä»¶ã‚³ãƒ¼ãƒ‰ (ã‚ªãƒ¼ãƒ—ãƒ³/Aç´š/3æ­³æœªå‹åˆ©ãªã©)
    "ç«¶èµ°æ¡ä»¶åç§°A": "race_condition_name_a", # ç«¶èµ°æ¡ä»¶åç§°A (ç°¡æ˜“ç‰ˆ)
    "ç«¶èµ°æ¡ä»¶åç§°": "race_condition_name", # ç«¶èµ°æ¡ä»¶åç§° (æ­£å¼ç‰ˆ)
    "é ­æ•°": "num_horses", # å‡ºèµ°é ­æ•°
    "åˆå‡ºèµ°é ­æ•°": "num_first_runners", # åˆå‡ºèµ°é ­æ•° (åŒãƒ¬ãƒ¼ã‚¹å†…)
    "é€ƒã’é¦¬é ­æ•°": "num_front_runners", # é€ƒã’é¦¬é ­æ•° (åŒãƒ¬ãƒ¼ã‚¹å†…)
    "é‡é‡ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰": "weight_type_code", # é‡é‡ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰ (ãƒãƒ³ãƒ‡/åˆ¥å®š/å®šé‡)

    # --- é¦¬ã®åŸºæœ¬æƒ…å ± (Horse Basic Info) ---
    "é¦¬ç•ª": "horse_number", # é¦¬ç•ª
    "é¦¬ç•ª2": "horse_number_v2", # é¦¬ç•ª2 (åˆ¥ã®è¡¨ç¾ï¼Ÿ)
    "æ€§åˆ¥ã‚³ãƒ¼ãƒ‰": "sex_code", # æ€§åˆ¥ã‚³ãƒ¼ãƒ‰
    "é¦¬é½¢": "horse_age", # é¦¬é½¢ (æ•´æ•°)
    "ç«¶èµ°é¦¬å¹´é½¢": "horse_age_dec", # ç«¶èµ°é¦¬å¹´é½¢ (å°æ•°ã€ä¾‹: 3.5æ­³)
    "ã‚­ãƒ£ãƒªã‚¢": "career", # ç·ã‚­ãƒ£ãƒªã‚¢å‡ºèµ°å›æ•°
    "ã‚­ãƒ£ãƒªã‚¢3": "career_v3", # ã‚­ãƒ£ãƒªã‚¢3 (åˆ¥ã®å®šç¾©ï¼Ÿ)
    "ã‚­ãƒ£ãƒªã‚¢3å¹³å‡": "career_v3_mean", # ã‚­ãƒ£ãƒªã‚¢3å¹³å‡
    "é¦¬ä½“é‡": "body_weight", # é¦¬ä½“é‡ (kg)
    "é¦¬ä½“é‡å¢—æ¸›": "body_weight_diff", # é¦¬ä½“é‡å¢—æ¸› (kg) (å‰èµ°æ¯”)
    "è² æ‹…é‡é‡": "weight_carried", # è² æ‹…é‡é‡ (kg)
    "è·é›¢å¢—æ¸›": "distance_change", # è·é›¢å¢—æ¸› (m) (å‰èµ°æ¯”)
    "ä¼‘é¤Šé€±æ•°": "rest_weeks", # ä¼‘é¤Šé€±æ•° (å‰èµ°ã‹ã‚‰)
    "ä¼‘é¤Šå¾Œå‡ºèµ°å›æ•°": "runs_since_layoff", # ä¼‘é¤Šå¾Œå‡ºèµ°å›æ•°
    "è»¢å©": "stable_transfer_flag", # è»¢å©ãƒ•ãƒ©ã‚°
    "é¦¬è¨˜å·ã‚³ãƒ¼ãƒ‰": "horse_mark_code", # é¦¬è¨˜å·ã‚³ãƒ¼ãƒ‰ (ã‚¢ãƒ­ãƒ¼ãªã©)
    "æ¯›è‰²ã‚³ãƒ¼ãƒ‰": "coat_color_code", # æ¯›è‰²ã‚³ãƒ¼ãƒ‰
    "ç”Ÿç”£è€…å": "breeder_name", # ç”Ÿç”£è€…å
    "ç”£åœ°å": "birthplace", # ç”£åœ°å
    "é¦¬ä¸»å": "owner_name", # é¦¬ä¸»å
    "é€£å¯¾ç‡": "place_rate", # ç”Ÿæ¶¯é€£å¯¾ç‡ (å˜ä½“é¦¬ã®è¤‡å‹ç‡?)
    "ä»Šå›ã®è·é›¢é€£å¯¾ç‡": "place_rate_distance", # ä»Šå›è·é›¢ã§ã®é€£å¯¾ç‡
    "ä»Šå›ã®è·é›¢å‡ºèµ°æ¯”ç‡": "start_ratio_distance", # ä»Šå›è·é›¢ã§ã®å‡ºèµ°æ¯”ç‡
    "åˆå‡ºèµ°å ´ã‚³ãƒ¼ãƒ‰": "first_race_venue_code", # åˆå‡ºèµ°ç«¶é¦¬å ´ã‚³ãƒ¼ãƒ‰
    "æ‰€å±": "training_center", # æ‰€å± (ç¾æµ¦/æ —æ±ãªã©)

    # --- ã‚ªãƒƒã‚ºãƒ»é…å½“æƒ…å ± (Odds / Payout Info) ---
    "å˜å‹ã‚ªãƒƒã‚º": "win_odds", # å˜å‹ã‚ªãƒƒã‚º (ç¢ºå®šã‚ªãƒƒã‚ºã«è¿‘ã„ã‚‚ã®)
    "å˜å‹é…å½“": "win_payout", # å˜å‹é…å½“ (ç¢ºå®š)
    "è¤‡å‹é…å½“": "place_payout", # è¤‡å‹é…å½“ (ç¢ºå®š)
    "è¤‡å‹ã‚ªãƒƒã‚º1": "place_odds_1", # è¤‡å‹ã‚ªãƒƒã‚º1 (ç¢ºå®šã‚ªãƒƒã‚ºã«è¿‘ã„ã‚‚ã®)
    "å˜å‹äººæ°—": "win_popularity", # å˜å‹äººæ°— (ç¢ºå®šäººæ°—ã«è¿‘ã„ã‚‚ã®)
    "å˜å‹æ”¯æŒç‡": "win_support_rate", # å˜å‹æ”¯æŒç‡ (ç¢ºå®šæ”¯æŒç‡ã«è¿‘ã„ã‚‚ã®)
    "ä¸‰é€£å˜æ”¯æŒç‡": "trifecta_support_rate", # ä¸‰é€£å˜æ”¯æŒç‡ (ç¢ºå®šæ”¯æŒç‡ã«è¿‘ã„ã‚‚ã®)
    "å˜å‹æ”¯æŒç‡å·®": "win_support_rate_diff", # å˜å‹æ”¯æŒç‡å·®
    "å˜å‹æ¯”ç‡": "win_ratio", # å˜å‹æ¯”ç‡
    "äºˆæƒ³ã‚ªãƒƒã‚º": "pred_odds", # äºˆæƒ³ã‚ªãƒƒã‚º (é¦¬ç‹Zãªã©äº‹å‰è¨ˆç®—)
    "äºˆæƒ³äººæ°—": "pred_popularity", # äºˆæƒ³äººæ°— (é¦¬ç‹Zãªã©äº‹å‰è¨ˆç®—)
    "æœ¬è³é‡‘1": "prize_money_1", # æœ¬è³é‡‘1ç€é¡
    "å˜å‹æ¨å®šã‚ªãƒƒã‚º": "implied_win_odds",   # ä¸‰é€£å˜æ”¯æŒç‡ã‹ã‚‰é€†ç®—ã—ãŸå˜å‹ã‚ªãƒƒã‚º
    "è¤‡å‹æ¨å®šã‚ªãƒƒã‚º": "implied_place_odds", # ä¸‰é€£å˜æ”¯æŒç‡ã‹ã‚‰é€†ç®—ã—ãŸè¤‡å‹ã‚ªãƒƒã‚º

    # --- ç€é †æƒ…å ± (Finishing Position Info) ---
    "ç¢ºå®šç€é †": "finishing_position",
    "å‰èµ°ç€é †": "last_finish",
    "å‰èµ°ç€é †A": "last_finish_a",
    "å‰ã€…èµ°ç€é †": "two_back_finish",
    "ä¸‰å‰èµ°ç€é †": "three_back_finish",

    # --- äºˆæƒ³/è©•ä¾¡/æŒ‡æ•° (Prediction / Evaluation / Index) ---
    "ã‚¿ã‚¤ãƒ æŒ‡æ•°": "time_index",
    "äºˆæƒ³ã‚¿ã‚¤ãƒ æŒ‡æ•°": "pred_time_index",
    "äºˆæƒ³ã‚¿ã‚¤ãƒ åå·®å€¤": "pred_time_dev",
    "äºˆæƒ³ã‚¿ã‚¤ãƒ æŒ‡æ•°é †ä½": "pred_time_index_rank",
    "äºˆæƒ³ãƒ€ãƒƒã‚·ãƒ¥æŒ‡æ•°": "pred_dash_index",
    "äºˆæƒ³ãƒ€ãƒƒã‚·ãƒ¥æŒ‡æ•°A": "pred_dash_index_A",
    "äºˆæƒ³ãƒ€ãƒƒã‚·ãƒ¥æŒ‡æ•°é †ä½": "pred_dash_rank",
    "å¾—ç‚¹": "score",
    "å¾—ç‚¹åå·®å€¤": "score_dev",
    "å¾—ç‚¹æ¨™æº–åå·®A": "score_std_a",
    "å¾—ç‚¹æ¨™æº–åå·®": "score_std",
    "å¾—ç‚¹W": "score_w",
    "å¾—ç‚¹ver3": "score_ver3",
    "å¾—ç‚¹V1": "score_v1",
    "å¾—ç‚¹V2": "score_v2",
    "å¾—ç‚¹V3": "score_v3",
    "å¾—ç‚¹V1é †ä½": "score_v1_rank",
    "å¾—ç‚¹V2é †ä½": "score_v2_rank",
    "å¾—ç‚¹V3é †ä½": "score_v3_rank",
    "é¦¬åˆ¸è©•ä¾¡é †ä½": "bet_eval_rank",
    "é¦¬åˆ¸è©•ä¾¡é †ä½B": "bet_eval_rank_b",
    "äºˆæƒ³å‹ã¡æŒ‡æ•°": "pred_win_index",
    "å…ˆè¡ŒæŒ‡æ•°": "early_speed_index",
    "å…ˆè¡ŒæŒ‡æ•°é †ä½": "early_speed_rank",
    "å…ˆè¡ŒæŒ‡æ•°A": "early_speed_index_a",
    "äºˆæƒ³ã‚¿ã‚¤ãƒ å¹³å‡": "pred_time_mean",
    "é¨æ‰‹è©•ä¾¡": "jockey_rating",
    "èª¿æ•™å¸«è©•ä¾¡": "trainer_rating",
    "æ é †è©•ä¾¡": "draw_rating",
    "è„šè³ªè©•ä¾¡": "running_style_rating",
    "ä¸€ç•ªäººæ°—ä¿¡é ¼åº¦": "fav_confidence",
    "ç«¶é¦¬å ´ãƒ©ãƒ³ã‚¯": "venue_rank",
    "ãƒ‘ãƒ‰ãƒƒã‚¯è©•ä¾¡": "paddock_rating",
    "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¾—ç‚¹": "default_score",
    "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå¾—ç‚¹é †ä½": "default_score_rank",
    "äºˆæƒ³å±•é–‹": "pred_race_shape",
    "æ å±•é–‹": "draw_development",
    "å±•é–‹å·®": "development_diff",
    "ãƒšãƒ¼ã‚¹å±•é–‹": "pace_development",

    # --- éå»èµ°æƒ…å ± (Past Race Info) ---
    "å‰èµ°é ­æ•°": "last_field_size",
    "å‰èµ°å ´ã‚³ãƒ¼ãƒ‰": "last_venue_code",
    "å‰èµ°ãƒšãƒ¼ã‚¹åå·®å€¤": "last_pace_dev",
    "å‰èµ°å±•é–‹": "last_race_shape",
    "å‰èµ°ä¸ŠãŒã‚Šé †ä½": "last_final_3f_rank",
    "å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°": "last_time_index",
    "å‰èµ°å¾—ç‚¹": "last_score",
    "å‰ã€…èµ°äººæ°—": "two_back_popularity",
    "å‰ã€…èµ°ãƒšãƒ¼ã‚¹åå·®å€¤": "two_back_pace_dev",
    "å‰ã€…èµ°å±•é–‹": "two_back_race_shape",
    "å‰ã€…èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°": "two_back_time_index",
    "ä¸‰å‰èµ°äººæ°—": "three_back_popularity",
    "ä¸‰å‰èµ°ãƒšãƒ¼ã‚¹åå·®å€¤": "three_back_pace_dev",
    "ä¸‰å‰èµ°å±•é–‹": "three_back_race_shape",
    "ä¸‰å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°": "three_back_time_index",
    "å››å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°": "four_back_time_index",
    "äº”å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°": "five_back_time_index",
    "éå»5èµ°ã®æœ€é«˜ã‚¿ã‚¤ãƒ æŒ‡æ•°": "best_time_index_last5",
    "éå»5èµ°ã®æœ€é«˜ã‚¿ã‚¤ãƒ æŒ‡æ•°é †ä½": "best_time_index_rank_last5",
    "æœ€é«˜ã‚¿ã‚¤ãƒ æŒ‡æ•°ã‹ã‚‰ä½•æˆ¦ç›®": "races_since_best_time_idx",
    "æŒã¡ã‚¿ã‚¤ãƒ é †ä½": "personal_best_time_rank",
    "ã‚¿ã‚¤ãƒ æŒ‡æ•°ä¸Šæ˜‡ä¿‚æ•°": "time_index_gain_coef",
    "ã‚¿ã‚¤ãƒ æŒ‡æ•°å›å¸°æ¨å®šå€¤": "time_index_reg_est",
    "ã‚¿ã‚¤ãƒ æŒ‡æ•°å›å¸°æ¨™æº–åå·®": "time_index_reg_std",
    "å‰èµ°ä¼‘é¤Šé€±æ•°": "last_layoff_weeks",
    "å‰èµ°æ›œæ—¥ã‚³ãƒ¼ãƒ‰": "last_weekday_code",
    "å‰èµ°ãƒšãƒ¼ã‚¹": "last_pace_text",
    "ã‚¿ã‚¤ãƒ æŒ‡æ•°ä¸Šæ˜‡ä¿‚æ•°A": "time_index_gain_coef_a",
    "ã‚¿ã‚¤ãƒ æŒ‡æ•°å›å¸°æ¨å®šå€¤A": "time_index_reg_est_a",
    "ã‚¿ã‚¤ãƒ æŒ‡æ•°å›å¸°æ¨™æº–åå·®A": "time_index_reg_std_a",
    "å‰èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°A": "last_time_index_a",
    "å‰ã€…èµ°ã‚¿ã‚¤ãƒ æŒ‡æ•°A": "two_back_time_index_a",
    "éå»5èµ°ã®æœ€é«˜ã‚¿ã‚¤ãƒ æŒ‡æ•°A": "best_time_index_last5_a",
    "å‰èµ°é¨æ‰‹è©•ä¾¡": "last_jockey_rating",
    "å‰èµ°äººæ°—": "last_popularity",
    "å‰èµ°äººæ°—ç€é †å·®": "last_pop_finish_diff",
    "å‰èµ°äººæ°—A": "last_popularity_a",
    "å‰èµ°ç€å·®": "last_margin",
    "å‰èµ°é¦¬ä½“é‡": "last_body_weight",
    "å‰èµ°ä¸­å¤®é¦¬æ•°": "last_race_jra_horses",
    "å‰èµ°ç«¶é¦¬å ´ãƒ©ãƒ³ã‚¯å·®": "last_venue_rank_diff",
    "å‰èµ°ç«¶é¦¬å ´åœ°åŸŸå": "last_venue_region",
    "å‰èµ°ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«": "last_race_level", # â† è¿½åŠ 
    "å‰èµ°ãƒ¬ãƒ¼ã‚¹ãƒ¬ãƒ™ãƒ«é †ä½": "last_race_level_rank", # â† è¿½åŠ 
    "ç«¶èµ°æ¡ä»¶ã‚¯ãƒ©ã‚¹": "race_class", #â†JRA05ã§è¿½åŠ 

    # --- é–¢ä¿‚è€…æƒ…å ± (Jockey/Trainer/Owner Info) ---
    "é¨æ‰‹ã‚³ãƒ¼ãƒ‰": "jockey_id",
    "èª¿æ•™å¸«ã‚³ãƒ¼ãƒ‰": "trainer_id",
    "èª¿æ•™å¸«æ±è¥¿æ‰€å±ã‚³ãƒ¼ãƒ‰": "trainer_region_code",
    "é¨æ‰‹æ±è¥¿æ‰€å±ã‚³ãƒ¼ãƒ‰": "jockey_region_code",
    "é¨æ‰‹å¹´é½¢": "jockey_age",
    "èª¿æ•™å¸«å¹´é½¢": "trainer_age",
    "é¨æ‰‹ãƒ©ãƒ³ã‚­ãƒ³ã‚°": "jockey_rank",
    "èª¿æ•™å¸«ãƒ©ãƒ³ã‚­ãƒ³ã‚°": "trainer_rank",
    "é¨æ‰‹ç›´è¿‘è¤‡å‹å›åç‡é †ä½": "jockey_recent_place_roi_rank",
    "é¨æ‰‹ç›´è¿‘è¤‡å‹å›åç‡": "jockey_recent_place_roi",
    "é¨æ‰‹ãƒã‚¹ã‚¿_åœ°åŸŸã‚³ãƒ¼ãƒ‰": "jockey_master_region_code",
    "èª¿æ•™å¸«ãƒã‚¹ã‚¿_åœ°åŸŸã‚³ãƒ¼ãƒ‰": "trainer_master_region_code",
    "é¨æ‰‹èª¿æ•™å¸«": "jockey_trainer_pair",

    # --- è¡€çµ±æƒ…å ± (Pedigree Info) ---
    "è¡€çµ±ç·åˆè©•ä¾¡": "bloodline_score",
    "è¡€çµ±ç·åˆè©•ä¾¡B": "pedigree_score_b",
    "è¡€çµ±è·é›¢è©•ä¾¡": "pedigree_distance_rating",
    "è¡€çµ±ãƒˆãƒ©ãƒƒã‚¯è©•ä¾¡": "pedigree_track_rating",
    "è¡€çµ±æˆé•·åŠ›è©•ä¾¡": "pedigree_growth_rating",
    "è¡€çµ±è·é›¢è©•ä¾¡B": "pedigree_distance_rating_b",
    "è¡€çµ±ãƒˆãƒ©ãƒƒã‚¯è©•ä¾¡B": "pedigree_track_rating_b",
    "è¡€çµ±æˆé•·åŠ›è©•ä¾¡B": "pedigree_growth_rating_b",
    "ç¹æ®–é¦¬å1": "bloodline1",
    "ç¹æ®–é¦¬å5": "bloodline5",

    # --- ãƒ¬ãƒ¼ã‚¹ãƒ»é¦¬ã®çŠ¶æ…‹/å¤‰åŒ– (Status / Change) ---
    "é¦¬å ´çŠ¶æ…‹ã‚³ãƒ¼ãƒ‰": "surface_state_code",
    "æ··åˆ": "mix_flag",
    "ã‚¯ãƒ©ã‚¹å¤‰å‹•": "class_change",
    "è¦‹ç¿’åŒºåˆ†": "apprentice_flag",
    "ãƒ†ãƒ³ä¹—ã‚Š": "first_time_jockey_flag",
    "å ´å¤‰æ›´": "venue_change",
    "ãƒˆãƒ©ãƒƒã‚¯å¤‰æ›´": "track_change",
    "å‰èµ°ç•°å¸¸åŒºåˆ†ã‚³ãƒ¼ãƒ‰": "last_anomaly_code",
    "é å¾": "travel_flag",
    "ç«¶é¦¬å ´åœ°åŸŸå¤‰åŒ–": "venue_region_change",
    "è»¢å©": "stable_transfer_flag",
    "ç«¶é¦¬å ´åœ°åŸŸå¤‰æ›´": "venue_region_changed", # â† è¿½åŠ 

    # --- å·®åˆ†/æ¯”ç‡/çµ±è¨ˆ (Difference / Ratio / Statistics) ---
    "äººæ°—é¦¬å¾—ç‚¹å·®": "fav_score_diff",
    "äºˆæƒ³å‹ã¡æŒ‡æ•°å·®": "pred_win_idx_diff",
    "æ³¢ä¹±åº¦": "upset_index",
    "å‡ºèµ°ã‚­ãƒ£ãƒªã‚¢å¹³å‡": "field_career_mean",
    "ã‚­ãƒ£ãƒªã‚¢å·®": "career_gap",
    "æ–¤é‡æ¯”": "weight_ratio",
    "å‰èµ°é ­æ•°å·®": "last_field_size_diff",
    "æœ€é«˜æŒ‡æ•°å·®": "best_index_diff",
    "é¦¬ç•ªç‡": "horse_number_ratio",
    "äºˆæƒ³ã‚¿ã‚¤ãƒ æŒ‡æ•°é †ä½ç‡": "pred_time_rank_ratio",
    "é¦¬åˆ¸è©•ä¾¡é †ä½ç‡": "bet_eval_rank_ratio",
    "äºˆæƒ³äººæ°—å·®": "pred_popularity_diff",
    "äººæ°—é¦¬åˆ¸å·®": "popularity_bet_diff",
    "é¦¬ä½“é‡é †ä½ç‡": "body_weight_rank_ratio",
    "å‰èµ°å¾—ç‚¹å·®": "last_score_diff",
    "é¨æ‰‹è©•ä¾¡å·®": "jockey_rating_diff",
    "æ é †è©•ä¾¡å·®": "draw_rating_diff",
    "å‰èµ°å ´ã‚³ãƒ¼ãƒ‰å·®": "last_venue_code_diff",
    "å‰ã€…èµ°äººæ°—ç€é †å·®": "two_back_pop_finish_diff",
    "ä¸‰å‰èµ°äººæ°—ç€é †å·®": "three_back_pop_finish_diff",
    "æ›œæ—¥å·®": "weekday_diff",
    "åˆå‡ºèµ°ç«¶é¦¬å ´ãƒ©ãƒ³ã‚¯": "first_race_venue_rank",

    # --- ãã®ä»– / ä¸æ˜ç­ (Other / Unclear) ---
    "1äººæ°—é¦¬ç•ªå·®": "fav_horse_rank_gap",
    "ãƒˆãƒ©ãƒƒã‚¯å": "track_name",
    "æ›œæ—¥ã‚³ãƒ¼ãƒ‰": "weekday_code",
    "æ å…¥ã‚Šé †": "stall_entry_order",
    "æ å…¥ã‚Šé †ç‡": "stall_entry_order_ratio",
    "äºˆæƒ³ã‚¿ã‚¤ãƒ æ¨™æº–åå·®A": "pred_time_std_a",
    "ä¸€ç•ªäººæ°—äºˆæƒ³å±•é–‹": "fav_pred_pace",
    "ä¸€ç•ªäººæ°—äºˆæƒ³å±•é–‹å·®": "fav_pace_gap",
    "ç«¶é¦¬å ´åœ°åŸŸå": "venue_region",
    "ä¸‰é€£å˜äººæ°—é †ä½":   "trifecta_popularity_rank",
    "æ‰€å±èª¿æ•™å¸«ã‚³ãƒ¼ãƒ‰": "trainer_affiliation_code",
    "é¦¬ä½“é‡é †ä½":       "body_weight_rank",
    "é¦¬ä½“é‡åå·®å€¤":     "body_weight_dev",
    "å‰èµ°æ é †è©•ä¾¡":     "last_draw_rating",
    "å¤©å€™ã‚³ãƒ¼ãƒ‰":         "weather_code",
    "äººæ°—é¦¬å¾—ç‚¹1":      "pop_horse_score1",
    "äººæ°—é¦¬æ”¯æŒç‡1":    "pop_horse_support_rate1",
    "äººæ°—é¦¬é¦¬åˆ¸è©•ä¾¡é †ä½1": "pop_horse_bet_eval_rank1",
    "æ³¢ä¹±åº¦2":         "upset_index2",
    "é¦¬ä½“é‡æ¨™æº–åå·®":     "body_weight_std",
    "ä¸€ç•ªäººæ°—é¦¬ç•ªå·®":     "fav_horse_number_diff",
    "é¦¬ä½“é‡åŒºåˆ†":       "body_weight_category",
    "ã‚¾ãƒ¼ãƒ³":            "zone",
    "POé¦¬":             "po_horse_flag",
    "ç©´ãã•":            "anagusa_flag",
    "èŠãƒ€é€£å¯¾æ¯”ç‡":     "turf_dirt_ratio_win_place",
    "éå»äººæ°—å¹³å‡":     "avg_past_popularity",
    "éå»ç€é †å¹³å‡":     "avg_past_finish_position",
    "éå»äººæ°—ç€é †å·®ç•°":     "past_pop_finish_gap",
    "ãƒ–ãƒªãƒ³ã‚«ãƒ¼":         "blinker_flag",
    "å‰èµ°ãƒ–ãƒªãƒ³ã‚«ãƒ¼":     "last_blinker_flag",
    "å‰èµ°ãƒã‚¤ãƒ‹ãƒ³ã‚°äºˆæƒ³é †ä½": "last_mining_pred_rank",
    "å½“æ—¥ä¹—æ›¿":            "jockey_change_today_flag",
    "ãƒ–ãƒªãƒ³ã‚«ãƒ¼å¤‰åŒ–":     "blinker_change_flag",
    "é¦¬å":              "horse_name",
    "ã‚³ãƒ¼ã‚¹åŒºåˆ†":       "corse_code",
    "å‰èµ°é¦¬ä½“é‡é †ä½": "prev_body_weight_rank",
    "å‰èµ°é¦¬ä½“é‡åå·®å€¤":               "prev_body_weight_stdscore",
    "å‰èµ°é¦¬ç•ª":                       "prev_horse_number",
    "å‰èµ°é¦¬ç•ªå·®":                       "diff_prev_horse_number",
    "é–‹å‚¬æ—¥é¦¬ç•ª":                       "date_horse_number",
    "å‰èµ°é–‹å‚¬æ—¥é¦¬ç•ª":                 "prev_date_horse_number",
    "å‰ã€…èµ°é–‹å‚¬æ—¥é¦¬ç•ª":               "prev2_date_horse_number",
    "é¨æ‰‹ç›´è¿‘è¤‡å‹å›åç‡é †ä½2":     "jockey_recent_place_return_rank2",
    "å‰èµ°ä¸åˆ©":                       "prev_trouble",
    "å‰èµ°é¨æ‰‹è©•ä¾¡å·®ç•°":               "diff_prev_jockey_rating",
    "é¦¬ä½“é‡é †ä½å·®":         "diff_body_weight_rank",
    "ç«¶èµ°æ¡ä»¶ç¨®åˆ¥ã‚³ãƒ¼ãƒ‰":            "race_condition_type_code",
    "äºˆæƒ³å±•é–‹å¹³å‡":                   "predicted_race_pace_avg",
    "äºˆæƒ³å±•é–‹å¹³å‡å·®":                 "predicted_race_pace_diff",
    "äºˆæƒ³å˜å‹æ¯”ç‡":                   "predicted_win_ratio",
    "ç”Ÿç”£è€…ã‚³ãƒ¼ãƒ‰":                   "breeder_code",
    "é¦¬ä¸»ã‚³ãƒ¼ãƒ‰":                     "owner_code",
    "è¡€çµ±ç™»éŒ²ç•ªå·":                   "bloodline_index",
    "æ ç•ª":                           "wakuban",
    "é¦¬åˆ¸å¤–æŒ‡æ•°":                     "baken_out"
}

# â”€â”€ é›†ç´„çµ±è¨ˆé‡è¨ˆç®—ã®å¯¾è±¡ã¨ã™ã‚‹åˆ— â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
AGGREGATION_TARGET_COLS = [
    "pred_time_index", "pred_dash_index", "score", "score_v3", "score_ver3",
    "pred_odds", "trifecta_support_rate",  "last_time_index",
    "body_weight","jockey_rating", "trainer_rating","baken_out"
]
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# â˜…ã€è¿½åŠ ã€‘POé¦¬ãƒ»ç©´ãã•ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰é–¢æ•°
def encode_marks(lf: pl.LazyFrame) -> pl.LazyFrame:
    """POé¦¬ãƒ»ç©´ãã•åˆ—ã‚’æ•°å€¤ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã€æ¬ æã‚’ 0 ã§åŸ‹ã‚ã‚‹ã€‚"""
    po_map  = {'0': 0, 'â˜†': 1, 'â˜…': 2}
    ana_map = {'0': 0, 'C': 1, 'B': 2, 'A': 3}
    if "po_horse_flag" not in lf.columns or "anagusa_flag" not in lf.columns:
        print("âš  POé¦¬ã¾ãŸã¯ç©´ãã•åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
        return lf
    return (
        lf
        .with_columns([
            pl.col("po_horse_flag").cast(pl.Utf8, strict=False).str.strip_chars().replace(po_map, default=0).cast(pl.Int8).alias("po_mark_rank"),
            pl.col("anagusa_flag").cast(pl.Utf8, strict=False).str.strip_chars().replace(ana_map, default=0).cast(pl.Int8).alias("anagusa_rank"),
        ])
        .drop(["po_horse_flag", "anagusa_flag"])
    )

# â”€â”€ util -----------------------------------------------------------------
norm = lambda s: _ud.normalize("NFKC", s).strip()
t0 = time.time()
log = lambda msg: print(f"â–¶ {msg:<34} {time.time()-t0:6.1f}s")

# â”€â”€ â‘¡ ãƒ˜ãƒƒãƒ€ 0 è¡Œèª­ã¿è¾¼ã¿ â†’ æ­£è¦åŒ– map ç”Ÿæˆ ------------------------------
with open(DATA_CSV, encoding="utf8", newline="") as f:
    reader = csv.reader(f)
    header_cols = next(reader)
norm_map = {c: norm(c) for c in header_cols}

# â”€â”€ â‘¢ LazyFrame èª­ã¿è¾¼ã¿ & æ­£è¦åŒ– rename ---------------------------------
schema_fix = {"è»¢å©": pl.Utf8, "æ‰€å±": pl.Utf8, "ç©´ãã•": pl.Utf8, "POé¦¬": pl.Utf8, "ç«¶èµ°ã‚³ãƒ¼ãƒ‰": pl.Utf8, "è¡€çµ±ç™»éŒ²ç•ªå·": pl.Utf8}
lf = (
    pl.read_csv(
        DATA_CSV,
        encoding="utf8",
        infer_schema_length=5_000,
        schema_overrides=schema_fix,
        low_memory=False,
    )
    .lazy()
    .rename(norm_map)
)
log("read_csv â†’ lazy â†’ æ­£è¦åŒ– rename")

# â”€â”€ â‘£ æ—¥æœ¬èªâ†’è‹±èªãƒªãƒãƒ¼ãƒ  -------------------------------------------------
present_cols_after_norm = list(lf.schema.keys())
jp2en_norm = {norm(k): v for k, v in j2e.items()}
rename_map_jp2en = {jp: en for jp, en in jp2en_norm.items() if jp in present_cols_after_norm}
lf = lf.rename(rename_map_jp2en)
log("æ—¥æœ¬èªâ†’è‹±èªãƒªãƒãƒ¼ãƒ ")

# â”€â”€ â‘£-A ã€JRA05ä¿®æ­£ã€‘date ã®å‹å¤‰æ›ã‚¿ã‚¤ãƒŸãƒ³ã‚°ã‚’å‰å€’ã— ---------------------
if "date" in lf.schema:
    lf = lf.with_columns(pl.col("date").str.strptime(pl.Datetime, "%Y/%m/%d %H:%M:%S", strict=False))
    log("date åˆ—ã‚’ Datetime åŒ–")

# =============================================================================
# ã‚¿ã‚¤ãƒˆãƒ«: race_code ã‚’ 11æ¡ã®æ–‡å­—åˆ—ã¸å›ºå®šï¼ˆæ•°å€¤ãƒ»æ–‡å­—åˆ—ã®ä¸¡æ–¹ã«å®‰å…¨ï¼‰
# èª¬æ˜:
#  1) æ•°å€¤ãªã‚‰ Int64 ã¸ä¸¸ã‚ã¦ã‹ã‚‰æ–‡å­—åˆ—åŒ–ï¼ˆ".0" ã‚’ç¢ºå®Ÿã«é™¤å»ï¼‰
#  2) æ–‡å­—åˆ—ãªã‚‰ ".0" ã‚’æœ«å°¾ã ã‘å®‰å…¨ã«å–ã‚Šé™¤ã
#  3) éæ•°å­—ã¯é™¤å» â†’ 11æ¡ã‚¼ãƒ­åŸ‹ã‚
#  4) å¦¥å½“æ€§ç›£æŸ»ï¼ˆæœ«å°¾ 01..12ï¼‰
# =============================================================================
import re
_RC_LAST2_RE = r"^\d{9}(0[1-9]|1[0-2])$"

if "race_code" in lf.columns:
    rc_expr = (
        pl.when(pl.col("race_code").cast(pl.Int64, strict=False).is_not_null())
          # æ•°å€¤â†’æ•´æ•°â†’æ–‡å­—åˆ—ï¼ˆ".0"ã®å½±éŸ¿ã‚’å®Œå…¨é®æ–­ï¼‰
          .then(pl.col("race_code").cast(pl.Int64, strict=False).cast(pl.Utf8))
        .when(pl.col("race_code").cast(pl.Float64, strict=False).is_not_null())
          # ä¸‡ä¸€ Float ã®ã¾ã¾ã§ã‚‚æ•´æ•°åŒ–ã—ã¦ã‹ã‚‰æ–‡å­—åˆ—åŒ–
          .then(pl.col("race_code").cast(pl.Float64, strict=False).round(0).cast(pl.Int64).cast(pl.Utf8))
        .otherwise(
          # ã™ã§ã«æ–‡å­—åˆ—ãªã‚‰ã€æœ«å°¾ã® ".0" ã ã‘ã‚’å®‰å…¨ã«é™¤å»ï¼ˆä¸­é–“ã® '.' ã¯æ®‹ã‚‹æƒ³å®šãªã—ï¼‰
          pl.col("race_code").cast(pl.Utf8, strict=False).str.replace(r"\.0$", "")
        )
    )

    lf = lf.with_columns(
        rc_expr
         .str.replace_all(r"\D", "")  # å¿µã®ãŸã‚éæ•°å­—ã¯é™¤å»
         .str.zfill(11)               # 11æ¡ã«çµ±ä¸€ï¼ˆä¸è¶³åˆ†ã¯å·¦ã‚¼ãƒ­åŸ‹ã‚ï¼‰
         .alias("race_code")
    )
    log("race_code ã‚’ 11æ¡ã®æ–‡å­—åˆ—ã«å›ºå®šï¼ˆæ•°å€¤/æ–‡å­—åˆ—ã©ã¡ã‚‰ã‚‚å®‰å…¨ï¼‰")

    # å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæœ«å°¾ 01..12ï¼‰
    _bad = (
        lf.filter(~pl.col("race_code").str.contains(_RC_LAST2_RE))
          .select("date", "race_code", "race_number")
          .limit(5)
          .collect()
    )
    if _bad.height > 0:
        print("ğŸš¨ [Phase-1] race_code å½¢å¼ä¸æ­£ï¼ˆä¾‹ç¤º5ä»¶ï¼‰:")
        print(_bad)
        # å¿…è¦ãªã‚‰åœæ­¢:
        # raise RuntimeError("race_code ã®æœ«å°¾ãŒ 01..12 ã§ãªã„è¡Œã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚")
    else:
        log("race_code å½¢å¼ãƒã‚§ãƒƒã‚¯ï¼ˆ11æ¡ & æœ«å°¾01..12ï¼‰ã‚’é€šé")
else:
    raise RuntimeError("race_code åˆ—ãŒè¦‹å½“ãŸã‚Šã¾ã›ã‚“ã€‚ãƒãƒƒãƒ”ãƒ³ã‚°æ¼ã‚Œã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# â”€â”€ â‘£-B é¦¬åã‚’æ–‡å­—æ•°ã«å¤‰æ› -------------------------------------------
log("é¦¬åã‚’æ–‡å­—æ•°ç‰¹å¾´é‡ã«å¤‰æ›")
HORSE_NAME_COL = 'horse_name'
if HORSE_NAME_COL in lf.columns:
    lf = lf.with_columns(
        pl.col(HORSE_NAME_COL).str.len_chars().fill_null(0).alias('horse_name_length')
    ).drop(HORSE_NAME_COL)
    print(f"  âœ… ç‰¹å¾´é‡ 'horse_name_length' ã‚’ä½œæˆã—ã€'{HORSE_NAME_COL}' ã‚’å‰Šé™¤ã—ã¾ã—ãŸã€‚")
else:
    print(f"  - è­¦å‘Š: é¦¬ååˆ— '{HORSE_NAME_COL}' ãŒè¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸãŸã‚ã€æ–‡å­—æ•°ã¸ã®å¤‰æ›ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")

# â˜…ã€å¤‰æ›´ã€‘POé¦¬ãƒ»ç©´ãã•åˆ—ã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ ------------------------
lf = encode_marks(lf)
log("POé¦¬ãƒ»ç©´ãã•åˆ—ã‚’æ•°å€¤ã«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰")

# â”€â”€ â‘¤-A ã€JRA05ä¿®æ­£ã€‘ å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ç‰¹å¾´é‡ã‚’ä½œæˆ (2æ­³é¦¬ã‚’è¿½åŠ ) ----------------
log("å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ç‰¹å¾´é‡ã‚’ä½œæˆ")
if "horse_age" in lf.columns:
    lf = lf.with_columns(
        pl.when(pl.col("horse_age") == 2).then(pl.lit("2yo"))
        .when(pl.col("horse_age") == 3).then(pl.lit("3yo"))
        .otherwise(pl.lit("older")).alias("age_group")
    )
    log("âœ… å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ç‰¹å¾´é‡ (age_group) ã‚’è¿½åŠ å®Œäº†")
else:
    log("âš  horse_age åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å¹´é½¢ã‚°ãƒ«ãƒ¼ãƒ—ç‰¹å¾´é‡ã®ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—")

# â”€â”€ â‘¤-B ã€JRA05è¿½åŠ ã€‘ æ•°å€¤/ã‚«ãƒ†ã‚´ãƒªä¸¡ç”¨ç‰¹å¾´é‡ã®ã‚«ãƒ†ã‚´ãƒªç‰ˆã‚’ä½œæˆ â”€â”€
log("æ•°å€¤/ã‚«ãƒ†ã‚´ãƒªä¸¡ç”¨ç‰¹å¾´é‡ã®ã‚«ãƒ†ã‚´ãƒªç‰ˆã‚’ä½œæˆ")
# å¯¾è±¡ã¨ãªã‚‹åˆ—ã®ãƒªã‚¹ãƒˆ
cols_to_create_cat_version = [
    # ãƒ¬ãƒ¼ã‚¹é–¢é€£
    'venue_code', 'track_surface_code', 'track_code', 'distance',
    'meeting_order', 'day_order', 'race_type_code', 'race_condition_code',
    'race_condition_type_code', 'weather_code', 'surface_state_code',
#    'month','race_number',
    # é¦¬ãƒ»æ é–¢é€£
    'sex_code', 'horse_mark_code', 'coat_color_code',
#    'horse_number', 'wakuban',
    # çŠ¶æ…‹å¤‰åŒ–ãƒ»ãƒ•ãƒ©ã‚°
    'venue_change', 'track_change', 'class_change', 'mix_flag', 'apprentice_flag',
    'first_time_jockey_flag', 'travel_flag', 'last_anomaly_code',
    # é–¢ä¿‚è€…ID
    'jockey_region_code', 'trainer_region_code','trainer_affiliation_code',
#    'jockey_id', 'trainer_id', 'owner_code', 'breeder_code',
    # ãã®ä»–ï¼ˆé †ä½ãƒ»æŒ‡æ•°ãªã©ï¼‰
#    'upset_index', 'upset_index2',
#    'num_first_runners', 'num_front_runners',
#    'fav_confidence', 'pred_popularity', 'trifecta_popularity_rank',
#    'early_speed_rank', 'body_weight_rank', 'last_final_3f_rank',
#    'pred_dash_rank', 'last_venue_code', 'last_popularity', 'last_finish',
#    'two_back_popularity', 'two_back_finish', 'three_back_popularity',
#    'three_back_finish', 'stall_entry_order', 'weight_type_code'
]

cat_exprs = []
for col_name in cols_to_create_cat_version:
    if col_name in lf.columns:
        cat_exprs.append(pl.col(col_name).cast(pl.Utf8).fill_null("__NA__").alias(f"{col_name}_cat"))

if cat_exprs:
    lf = lf.with_columns(cat_exprs)
    log(f"âœ… ã‚«ãƒ†ã‚´ãƒªç‰ˆç‰¹å¾´é‡ ({len(cat_exprs)}åˆ—) ã‚’è¿½åŠ å®Œäº†")
else:
    log("âš  ã‚«ãƒ†ã‚´ãƒªç‰ˆç‰¹å¾´é‡ã®å¯¾è±¡åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")


# â”€â”€ â‘¤-B+1: é¦¬åˆ¸å¤–æŒ‡æ•°ã®æ­£è¦åŒ–ã¨ã‚¹ã‚³ã‚¢åŒ– â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("baken_out -> bgi_norm / bgi_score ã‚’è¿½åŠ ")

if "baken_out" in lf.columns:
    # CSVå´ãŒ 0â€“5 ã‹ 0â€“100 ã‹ã‚’è‡ªå‹•åˆ¤å®šï¼ˆ>10 ã‚’ 100ã‚¹ã‚±ãƒ¼ãƒ«æ‰±ã„ï¼‰
    _bgi_max = (
        lf.select(pl.col("baken_out").cast(pl.Float64).max().alias("_bmax"))
          .collect(streaming=True)["_bmax"][0]
    )
    _scale = 100.0 if (_bgi_max is not None and _bgi_max > 10) else 5.0

    lf = lf.with_columns([
        (pl.col("baken_out").cast(pl.Float32) / pl.lit(_scale))
            .clip(0.0, 1.0).alias("bgi_norm"),
        (pl.col("baken_out").cast(pl.Float32) * (100.0 / _scale))
            .alias("bgi_score"),
    ])
    # å¾Œæ®µâ‘¥-Dï¼ˆé›†ç´„çµ±è¨ˆé‡ï¼‰ã§å¹³å‡/åˆ†æ•£ãªã©ã‚’ä½œã‚‹ãŸã‚ã€é›†ç´„å¯¾è±¡ã«åŠ ãˆã‚‹
    if "bgi_norm" not in AGGREGATION_TARGET_COLS:
        AGGREGATION_TARGET_COLS.append("bgi_norm")

    log(f"âœ… bgi_norm/bgi_score è¿½åŠ ï¼ˆscale={_scale}ï¼‰")
else:
    log("âš  baken_out åˆ—ãŒç„¡ã„ãŸã‚ BGI è¿½åŠ ã‚’ã‚¹ã‚­ãƒƒãƒ—")



# â”€â”€ â‘¥ æ¬ æå€¤ã®å‡¦ç† (ãƒ•ãƒ©ã‚°ç”Ÿæˆ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ç‰¹å®šç³»çµ±ã®æ¬ æãƒ•ãƒ©ã‚°åˆ—ã®ä½œæˆã‚’é–‹å§‹")

# å¯¾è±¡ã¨ã™ã‚‹æ–‡å­—åˆ—ã®ãƒªã‚¹ãƒˆ
target_keywords = ["time_index", "race_shape", "popularity", "pace_dev", "last"]

# å¯¾è±¡ã¨ãªã‚‹åˆ—ã‚’ç‰¹å®š
cols_for_missing_flag = []
current_columns = lf.columns
for col in current_columns:
    dtype = lf.schema[col]
    if dtype in pl.NUMERIC_DTYPES: # æ•°å€¤å‹ã®ã¿ã‚’å¯¾è±¡
        if any(keyword in col for keyword in target_keywords):
            cols_for_missing_flag.append(col)

# é‡è¤‡ã‚’å‰Šé™¤
cols_for_missing_flag = sorted(list(set(cols_for_missing_flag)))

missing_flag_exprs = [pl.col(c).is_null().cast(pl.Int8).alias(f"{c}_is_missing") for c in cols_for_missing_flag]

if missing_flag_exprs:
    lf = lf.with_columns(missing_flag_exprs)
    log(f"ç‰¹å®šç³»çµ±ã®æ¬ æãƒ•ãƒ©ã‚°åˆ— ({len(cols_for_missing_flag)}åˆ—) ã‚’è¿½åŠ å®Œäº†")
else:
    log("æ¬ æãƒ•ãƒ©ã‚°ä½œæˆã®å¯¾è±¡åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# â”€â”€ â‘¥-B ã€JRA05è¿½åŠ ã€‘ ãƒ“ãƒ³åŒ–ç‰¹å¾´é‡ã®ä½œæˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ãƒ“ãƒ³åŒ–ç‰¹å¾´é‡ã®ä½œæˆã‚’é–‹å§‹")
binning_exprs = []
# distance_change ã®ãƒ“ãƒ³åŒ–
if "distance_change" in lf.columns:
    binning_exprs.append(
        pl.when(pl.col("distance_change") == 0).then(pl.lit(0, dtype=pl.Int8))
        .when(pl.col("distance_change").abs() <= 400).then(2 * pl.col("distance_change").sign())
        .otherwise(3 * pl.col("distance_change").sign())
        .cast(pl.Int8)
        .alias("distance_change_bin")
    )
# score ã®ãƒ“ãƒ³åŒ–
if "score" in lf.columns:
    binning_exprs.append(
        pl.when(pl.col("score") <= 30).then(pl.lit(0, dtype=pl.Int8))
        .when(pl.col("score") <= 40).then(pl.lit(1, dtype=pl.Int8))
        .when(pl.col("score") <= 50).then(pl.lit(2, dtype=pl.Int8))
        .when(pl.col("score") <= 54).then(pl.lit(3, dtype=pl.Int8))
        .when(pl.col("score") <= 57).then(pl.lit(4, dtype=pl.Int8))
        .otherwise(pl.lit(5, dtype=pl.Int8))
        .alias("score_bin")
    )

if binning_exprs:
    lf = lf.with_columns(binning_exprs)
    log(f"âœ… ãƒ“ãƒ³åŒ–ç‰¹å¾´é‡ ({len(binning_exprs)}åˆ—) ã‚’è¿½åŠ å®Œäº†")



# â”€â”€ â‘¥-D ãƒ¬ãƒ¼ã‚¹å†…é›†ç´„çµ±è¨ˆé‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ãƒ¬ãƒ¼ã‚¹å†…é›†ç´„çµ±è¨ˆé‡ã®è¨ˆç®—ã‚’é–‹å§‹")
race_keys = ["date", "race_code", "race_number"]  # ãƒ¬ãƒ¼ã‚¹è­˜åˆ¥ã‚­ãƒ¼
schema_after_drop = lf.schema
schema_names        = list(schema_after_drop.keys())
effective_agg_cols = [c for c in AGGREGATION_TARGET_COLS if c in schema_names and schema_after_drop[c] in pl.NUMERIC_DTYPES]
if not effective_agg_cols:
    log("ãƒ¬ãƒ¼ã‚¹å†…é›†ç´„çµ±è¨ˆé‡ã‚’è¨ˆç®—ã™ã‚‹æœ‰åŠ¹ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“")
else:
    agg_expressions = []
    for col in effective_agg_cols:
        agg_expressions += [
            pl.col(col).sum().alias(f"{col}_race_sum"),
            pl.col(col).mean().alias(f"{col}_race_mean"),
            pl.col(col).var().alias(f"{col}_race_var"),
            pl.col(col).std().alias(f"{col}_race_std"),
            pl.col(col).max().alias(f"{col}_race_max"),
            pl.col(col).min().alias(f"{col}_race_min"),
            (pl.col(col).max() - pl.col(col).min()).alias(f"{col}_race_range"),
            pl.col(col).skew().fill_nan(None).alias(f"{col}_race_skew"),
            pl.col(col).kurtosis().fill_nan(None).alias(f"{col}_race_kurt"),
        ]
    cols_to_collect_for_agg = race_keys + effective_agg_cols
    df_tmp_agg = lf.select(cols_to_collect_for_agg).collect(streaming=True)
    stats_df = df_tmp_agg.group_by(race_keys, maintain_order=True).agg(agg_expressions)
    log(f"ãƒ¬ãƒ¼ã‚¹ã”ã¨ã®çµ±è¨ˆé‡ã‚’è¨ˆç®— ({len(effective_agg_cols)}åˆ—ã‹ã‚‰)")
    lf = lf.join(stats_df.lazy(), on=race_keys, how="left", coalesce=True)
    log(f"ãƒ¬ãƒ¼ã‚¹å†…é›†ç´„çµ±è¨ˆé‡åˆ— ({len(effective_agg_cols)*9}åˆ—) ã‚’è¿½åŠ ")

# â”€â”€ â‘¥-E ã€JRA05è¿½åŠ ã€‘ãƒ¬ãƒ¼ã‚¹å†…ç›¸å¯¾ç‰¹å¾´é‡ã®æ±ç”¨ãƒ–ãƒ­ãƒƒã‚¯ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ãƒ¬ãƒ¼ã‚¹å†…ç›¸å¯¾ç‰¹å¾´é‡ã®æ±ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã‚’é–‹å§‹")
RELATIVE_TARGET_COLS = [
    "pred_time_index", "pred_dash_index", "score", "pred_odds", "trifecta_support_rate",
    "weight_carried", "last_time_index", "two_back_time_index", "three_back_time_index",
    "last_pace_dev", "body_weight", "place_rate", "last_race_level", "weight_ratio",
    "jockey_rating", "trainer_rating",
    "bgi_norm",  # â† è¿½åŠ ï¼ˆå¤§ãã„ã»ã©â€œé¦¬åˆ¸å¤–å¯„ã‚Šâ€ï¼‰
]
RANK_DESC_MAP = {  # True=é™é †ï¼ˆå¤§ãã„ã»ã©è‰¯ã„ï¼‰
    "pred_time_index": True, "pred_dash_index": True, "score": True,
    "trifecta_support_rate": True, "last_time_index": True, "two_back_time_index": True,
    "three_back_time_index": True, "body_weight": True, "place_rate": True,
    "last_race_level": True, "jockey_rating": True, "trainer_rating": True,
    "pred_odds": False, "weight_carried": False, "last_pace_dev": False, "weight_ratio": False,
    "bgi_norm": True,  # â† é«˜ã„ã»ã©æ‚ªã„ï¼é™é †ã§ä¸Šä½ï¼ˆ=å±é™ºåº¦ãŒé«˜ã„ï¼‰
}

# --- ã‚¹ãƒ†ãƒƒãƒ—1: rank åˆ—ã‚’å…ˆã«ä½œæˆ ---
rank_exprs = []
for col in RELATIVE_TARGET_COLS:
    if col in lf.columns:
        rank_col_name = f"{col}_rank_in_race"
        rank_exprs.append(
            pl.col(col).rank(method="average", descending=RANK_DESC_MAP.get(col, True)).over(race_keys)
              .alias(rank_col_name)
        )
if rank_exprs:
    lf = lf.with_columns(rank_exprs)

# --- ã‚¹ãƒ†ãƒƒãƒ—2: rankåˆ—ã‚„é›†ç´„çµ±è¨ˆé‡ã‚’ä½¿ã£ã¦ä»–ã®ç›¸å¯¾ç‰¹å¾´é‡ã‚’ä½œæˆ ---
other_relative_exprs = []
eps = 1e-6
for col in RELATIVE_TARGET_COLS:
    if col in lf.columns:
        rank_col_name = f"{col}_rank_in_race"
        mean_col = f"{col}_race_mean"
        std_col  = f"{col}_race_std"
        min_col = f"{col}_race_min"
        max_col = f"{col}_race_max"
        is_desc = RANK_DESC_MAP.get(col, True)

        # rank_ratio, is_top1, is_top3
        if rank_col_name in lf.columns:
            other_relative_exprs.append(
                ((pl.col(rank_col_name) - 1) / (pl.len().over(race_keys) - 1).clip(lower_bound=1))
                  .clip(0.0, 1.0).fill_nan(0.0).alias(f"{col}_rank_ratio")
            )
            other_relative_exprs.append((pl.col(rank_col_name) == 1).cast(pl.Int8).alias(f"{col}_is_top1"))
            other_relative_exprs.append((pl.col(rank_col_name) <= 3).cast(pl.Int8).alias(f"{col}_is_top3"))

        # diff_from_mean / z_in_race
        if mean_col in lf.columns:
            other_relative_exprs.append( (pl.col(col) - pl.col(mean_col)).alias(f"{col}_diff_from_mean") )
            if std_col in lf.columns:
                other_relative_exprs.append( ((pl.col(col) - pl.col(mean_col)) / (pl.col(std_col) + eps))
                                .alias(f"{col}_z_in_race") )
        # diff_to_top / share_of_top (å‘ãã‚’è€ƒæ…®)
        if max_col in lf.columns and min_col in lf.columns:
            other_relative_exprs.append(
                pl.when(is_desc)
                  .then(pl.col(max_col) - pl.col(col))
                  .otherwise(pl.col(col) - pl.col(min_col))
                  .alias(f"{col}_diff_to_top")
            )
            other_relative_exprs.append(
                pl.when(is_desc)
                  .then(pl.col(col) / (pl.col(max_col) + eps))
                  .otherwise((pl.col(min_col) + eps) / (pl.col(col) + eps))
                  .alias(f"{col}_share_of_top")
            )

if other_relative_exprs:
    lf = lf.with_columns(other_relative_exprs)

log(f"ãƒ¬ãƒ¼ã‚¹å†…ç›¸å¯¾ç‰¹å¾´é‡ã‚’ {len(RELATIVE_TARGET_COLS)} ç¨®ã«ä»˜ä¸å®Œäº†")


# â”€â”€ â‘¥-E+Î±: bgi ã®ãƒ¡ãƒ‡ã‚£ã‚¢ãƒ³ä¹–é›¢ï¼ˆãƒ¬ãƒ¼ã‚¹å†…ä¸­å¤®å€¤ã¨ã®å·®ï¼‰ã ã‘å€‹åˆ¥è¿½åŠ 
if "bgi_norm" in lf.columns:
    rk = ["date", "race_code", "race_number"]
    lf = lf.with_columns(
        (pl.col("bgi_norm") - pl.col("bgi_norm").median().over(rk)).alias("bgi_gap_med")
    )
    log("bgi_gap_med ã‚’è¿½åŠ ï¼ˆbgi_norm âˆ’ median_in_raceï¼‰")



# â”€â”€ â‘¥-G ã€JRA05è¿½åŠ ã€‘ãƒˆãƒƒãƒ—ç‹¬èµ°åº¦ã®ãƒ¬ãƒ¼ã‚¹å®šæ•° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("ãƒˆãƒƒãƒ—ç‹¬èµ°åº¦ã®ãƒ¬ãƒ¼ã‚¹å®šæ•°ã‚’ä½œæˆ")
top_margin_cols = ["trifecta_support_rate", "pred_odds","pred_time_index","pred_dash_index","score","score_ver3"]
top_margin_exprs = []
for col in top_margin_cols:
    if col in lf.columns:
        is_desc = RANK_DESC_MAP.get(col, True)
        top_val = pl.col(col).sort(descending=is_desc).first().over(race_keys)
        second_val = pl.col(col).sort(descending=is_desc).slice(1, 1).first().over(race_keys)
        margin_expr = (top_val - second_val).abs().alias(f"{col}_top_margin_in_race")
        top_margin_exprs.append(margin_expr)
        top_margin_exprs.append((margin_expr / (top_val.abs() + eps)).alias(f"{col}_top_margin_norm_in_race"))

if top_margin_exprs:
    lf = lf.with_columns(top_margin_exprs)
    log(f"âœ… ãƒˆãƒƒãƒ—ç‹¬èµ°åº¦ç‰¹å¾´é‡ ({len(top_margin_exprs)}åˆ—) ã‚’è¿½åŠ å®Œäº†")

# â”€â”€ â‘¦-B ã€è¿½åŠ ã€‘ å††ç’°ç‰¹å¾´é‡ ------------------------------------------------
lf = lf.with_columns([
    (pl.col("date").dt.month()  / 12 * 2 * math.pi).sin().alias("month_sin"),
    (pl.col("date").dt.month()  / 12 * 2 * math.pi).cos().alias("month_cos"),
    (pl.col("date").dt.weekday() / 7 * 2 * math.pi).sin().alias("wday_sin"),
    (pl.col("date").dt.weekday() / 7 * 2 * math.pi).cos().alias("wday_cos"),
    (pl.col("date").dt.week()      / 52 * 2 * math.pi).sin().alias("week_sin"),
    (pl.col("date").dt.week()      / 52 * 2 * math.pi).cos().alias("week_cos"),
])
log("å††ç’°ç‰¹å¾´é‡ (month, wday, week) ã‚’è¿½åŠ ")

# â”€â”€ â‘¦-B-2 ã€JRA05è¿½åŠ ã€‘ å­£ç¯€ç‰¹å¾´é‡ ------------------------------------------------
log("å­£ç¯€ç‰¹å¾´é‡ã‚’è¿½åŠ ")
if "month" in lf.columns:
    lf = lf.with_columns(
        pl.when(pl.col("month").is_in([3, 4, 5])).then(pl.lit("Spring"))
        .when(pl.col("month").is_in([6, 7, 8])).then(pl.lit("Summer"))
        .when(pl.col("month").is_in([9, 10, 11])).then(pl.lit("Autumn"))
        .otherwise(pl.lit("Winter"))
        .alias("season")
    )
    log("âœ… å­£ç¯€ç‰¹å¾´é‡ (season) ã‚’è¿½åŠ å®Œäº†")
else:
    log("âš  month åˆ—ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€å­£ç¯€ç‰¹å¾´é‡ã®ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—")

# â”€â”€ â˜…â˜…â˜… â‘¦-Cã€JRA05ä¿®æ­£ã€‘è·é›¢ãƒ“ãƒ³ã®å¤šå±¤åŒ– & venue_code ã¨ã®äº¤äº’ä½œç”¨ â”€â”€
log("è·é›¢ãƒ“ãƒ³ã®å¤šå±¤åŒ–ã¨venueäº¤äº’ä½œç”¨ã‚’ä½œæˆ")
# --- è·é›¢ãƒ“ãƒ³ã‚’å…ˆã«ä½œã‚‹ ---
if "distance" in lf.columns:
    lf = lf.with_columns([
#        (((pl.col("distance") + 100) // 200) * 200).cast(pl.Int32).alias("distance_bin_200"),
        (((pl.col("distance") + 200) // 400) * 400).cast(pl.Int32).alias("distance_bin_400"),
#        ((pl.col("distance") // 1000) * 1000).cast(pl.Int32).alias("distance_family_1000"),
        pl.when(pl.col("distance") < 1400).then(pl.lit("spr"))
         .when(pl.col("distance") <= 1899).then(pl.lit("mile"))
         .when(pl.col("distance") <= 2399).then(pl.lit("inter"))
         .otherwise(pl.lit("stayer")).alias("distance_band4"),
        #ã€JRA05è¿½åŠ ã€‘è·é›¢ã®é€£ç¶šæ€§ã‚’å¼·åŒ–
        (pl.col("distance").cast(pl.Float64)).alias("dist_f"),
    ])
    lf = lf.with_columns([
        (pl.col("dist_f")/1000.0).alias("dist_km"),
        (pl.col("dist_f")**2).alias("dist_sq"),
        (pl.col("dist_f")**3).alias("dist_cu"),
    ])
    # --- è·é›¢ãƒ“ãƒ³ã‚’ä½¿ã£ã¦ã•ã‚‰ã«ç‰¹å¾´é‡ã‚’ä½œæˆ ---
    if "distance_band4" in lf.columns and "track_surface_code" in lf.columns:
        lf = lf.with_columns(
            (pl.col("track_surface_code").cast(pl.Utf8).fill_null("__NA__") + pl.lit("_") + pl.col("distance_band4").cast(pl.Utf8).fill_null("__NA__")).alias("surface_distance_band4")
        )

# --- ãã®å¾Œã« venue ã¨ã®äº¤äº’ä½œç”¨ã‚’ä½œã‚‹ ---
interaction_exprs = []
if "venue_code" in lf.schema:
    # æ—¢å­˜ã®äº¤äº’ä½œç”¨
    interaction_exprs.append(pl.col("venue_code").cast(pl.Utf8).fill_null("__NA__").alias("venue_code_str"))
    if "track_surface_code" in lf.schema:
        interaction_exprs.append(
            pl.concat_str([pl.col("venue_code").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("track_surface_code").cast(pl.Utf8).fill_null("__NA__")]).alias("venue_surface_combo")
        )
        # 3è¦ç´ ã®äº¤äº’ä½œç”¨ã‚’è¿½åŠ 
        if "distance_band4" in lf.schema:
            interaction_exprs.append(
                pl.concat_str([
                    pl.col("venue_code").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"),
                    pl.col("track_surface_code").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"),
                    pl.col("distance_band4").cast(pl.Utf8).fill_null("__NA__")
                ]).alias("venue_surface_distance_band_combo")
            )
    if "track_code" in lf.schema:
        interaction_exprs.append(
            pl.concat_str([pl.col("venue_code").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("track_code").cast(pl.Utf8).fill_null("__NA__")]).alias("venue_track_combo")
        )
    # è·é›¢ãƒ“ãƒ³ã¨ã®äº¤äº’ä½œç”¨ï¼ˆæ‹¡å¼µç‰ˆï¼‰
#    if "distance_bin_200" in lf.schema:
#        interaction_exprs.append(
#            pl.concat_str([pl.col("venue_code").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("distance_bin_200").cast(pl.Utf8).fill_null("__NA__")]).alias("venue_distance_bin")
#        )
#    if "distance_bin_400" in lf.schema:
#        interaction_exprs.append(
#            pl.concat_str([pl.col("venue_code").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("distance_bin_400").cast(pl.Utf8).fill_null("__NA__")]).alias("venue_distance400_bin")
#        )
    if "distance_band4" in lf.schema:
        interaction_exprs.append(
            pl.concat_str([pl.col("venue_code").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("distance_band4").cast(pl.Utf8).fill_null("__NA__")]).alias("venue_distance_band4")
        )

if interaction_exprs:
    lf = lf.with_columns(interaction_exprs)
    log("venue_code äº¤äº’ä½œç”¨ï¼ˆæ‹¡å¼µç‰ˆï¼‰ã‚’è¿½åŠ ")

    lf = lf.collect(streaming=True).lazy()
    log("materialize barrierï¼švenueäº¤äº’ä½œç”¨åˆ—ã‚’ç¢ºå®šï¼ˆcollectâ†’lazyï¼‰")
else:
    log("âš  venue_code äº¤äº’ä½œç”¨ã®ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¿…è¦åˆ—ãŒä¸è¶³ï¼‰")

# â”€â”€ â‘¦-C-2 ã€JRA05è¿½åŠ ã€‘ é–¢ä¿‚è€…ã®çµ„ã¿åˆã‚ã›ç‰¹å¾´é‡ ----------------------------------
log("é–¢ä¿‚è€…ã®çµ„ã¿åˆã‚ã›ç‰¹å¾´é‡ã‚’ä½œæˆ")
combo_exprs = []
required_cols_for_combo = ["jockey_id", "trainer_id", "owner_code"]
if all(c in lf.columns for c in required_cols_for_combo):
    combo_exprs.extend([
#        pl.concat_str([pl.col("jockey_id").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("trainer_id").cast(pl.Utf8).fill_null("__NA__")]).alias("jockey_trainer_combo"),
        pl.concat_str([pl.col("jockey_id").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("owner_code").cast(pl.Utf8).fill_null("__NA__")]).alias("jockey_owner_combo"),
#        pl.concat_str([pl.col("trainer_id").cast(pl.Utf8).fill_null("__NA__"), pl.lit("_"), pl.col("owner_code").cast(pl.Utf8).fill_null("__NA__")]).alias("trainer_owner_combo"),
    ])
    lf = lf.with_columns(combo_exprs)
    log("âœ… é¨æ‰‹ãƒ»èª¿æ•™å¸«ãƒ»é¦¬ä¸»ã®çµ„ã¿åˆã‚ã›ç‰¹å¾´é‡ (3åˆ—) ã‚’è¿½åŠ å®Œäº†")
else:
    log("âš  çµ„ã¿åˆã‚ã›ç‰¹å¾´é‡ã«å¿…è¦ãªåˆ— (jockey_id, trainer_id, owner_code) ãŒä¸è¶³ã—ã¦ã„ã‚‹ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")



# â”€â”€ â‘¦-D ã€è¿½åŠ ã€‘æ—¥å˜ä½ãƒ»ãƒ¬ãƒ¼ã‚¹å˜ä½ã®é »åº¦ç‰¹å¾´é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("æ—¥å˜ä½ãƒ»ãƒ¬ãƒ¼ã‚¹å˜ä½ã®é »åº¦ç‰¹å¾´é‡ã‚’è¿½åŠ ")
# å®‰å®šåŒ–ã®ãŸã‚ã€ä¸»è¦ãªã‚‚ã®ã«çµã‚‹
STABLE_FREQ_COLS = [
#    "venue_surface_distance_band_combo",
    "jockey_trainer_combo",
    "jockey_owner_combo", "trainer_owner_combo",
]

freq_exprs = []
if "date" in lf.schema and isinstance(lf.schema["date"], pl.datatypes.Datetime):
    # å…ƒã€…ã®é »åº¦ç‰¹å¾´é‡
    for id_col in ["jockey_id", "trainer_id", "owner_code", "breeder_code"]:
         if id_col in lf.columns:
            freq_exprs.append(pl.col(id_col).count().over([pl.col("date").dt.date(), id_col]).alias(f"{id_col}_day_freq"))
            freq_exprs.append(pl.col(id_col).count().over(["race_code", id_col]).alias(f"{id_col}_race_freq"))
    # ç›¸äº’ä½œç”¨ã®å‡ºç¾é‡
    # for id_col in STABLE_FREQ_COLS:
    #     if id_col in lf.columns:
    #         freq_exprs.append(pl.col(id_col).count().over([pl.col("date").dt.date(), id_col]).alias(f"{id_col}_day_freq"))

    if freq_exprs:
        lf = lf.with_columns(freq_exprs)
        log(f"é »åº¦ç‰¹å¾´é‡ ({len(freq_exprs)}åˆ—) ã‚’è¿½åŠ å®Œäº†")
    else:
        log("é »åº¦ç‰¹å¾´é‡ã®å¯¾è±¡åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
else:
    log("âš  dateåˆ—ãŒDatetimeå‹ã§ãªã„ãŸã‚ã€æ—¥å˜ä½ã®é »åº¦ç‰¹å¾´é‡ã®ä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")

# â”€â”€ â‘¦-E ã€JRA05è¿½åŠ ã€‘éå»èµ°ã‚«ãƒ©ãƒ ã‹ã‚‰ã®è¡Œå†…æ´¾ç”Ÿç‰¹å¾´é‡ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
log("éå»èµ°ã‚«ãƒ©ãƒ ã‹ã‚‰ä½œã‚‹è¡Œå†…æ´¾ç”Ÿç‰¹å¾´é‡ã‚’è¿½åŠ ")
# å¯¾è±¡ã‚«ãƒ©ãƒ å®šç¾©
FIN_COLS  = ["last_finish", "two_back_finish", "three_back_finish"]
TI3_COLS  = ["last_time_index", "two_back_time_index", "three_back_time_index"]
TI5_COLS  = TI3_COLS + ["four_back_time_index", "five_back_time_index"]
PACE_COLS = ["last_pace_dev", "two_back_pace_dev", "three_back_pace_dev"]
#SHAPE_COLS= ["last_race_shape", "two_back_race_shape", "three_back_race_shape"]
POP_COLS  = ["last_popularity", "two_back_popularity", "three_back_popularity"]
PFD_COLS  = ["last_pop_finish_diff", "two_back_pop_finish_diff", "three_back_pop_finish_diff"]

def _present(cols: list[str], frame) -> list[str]:
    return [c for c in cols if c in frame.columns]

past_race_exprs = []
# --- ç€é †ç³» ---
fin_av = _present(FIN_COLS, lf)
if fin_av:
    past_race_exprs.extend([
        pl.min_horizontal([pl.col(c) for c in fin_av]).alias("best_finish_last3"),
        pl.mean_horizontal([pl.col(c) for c in fin_av]).alias("avg_finish_last3"),
        pl.concat_list([pl.col(c) for c in fin_av]).list.eval(pl.element().std()).list.get(0).alias("std_finish_last3"),
        pl.concat_list([pl.col(c) for c in fin_av]).list.eval(pl.element().var()).list.get(0).alias("var_finish_last3"),
    ])
    if "last_finish" in fin_av and "two_back_finish" in fin_av:
        past_race_exprs.append((pl.col("two_back_finish") - pl.col("last_finish")).alias("finish_improve_L1_vs_L2"))

# --- ã‚¿ã‚¤ãƒ æŒ‡æ•°ç³» ---
ti5_av = _present(TI5_COLS, lf)
if ti5_av:
    past_race_exprs.extend([
        pl.max_horizontal([pl.col(c) for c in ti5_av]).alias("max_time_index_last5"),
        pl.mean_horizontal([pl.col(c) for c in ti5_av]).alias("mean_time_index_last5"),
        pl.concat_list([pl.col(c) for c in ti5_av]).list.eval(pl.element().std()).list.get(0).alias("std_time_index_last5"),
        pl.concat_list([pl.col(c) for c in ti5_av]).list.eval(pl.element().var()).list.get(0).alias("var_time_index_last5"),
    ])
ti3_av = _present(TI3_COLS, lf)
if "last_time_index" in ti3_av and "two_back_time_index" in ti3_av:
    past_race_exprs.append((pl.col("last_time_index") - pl.col("two_back_time_index")).alias("ti_trend_L1_minus_L2"))

# --- äººæ°—ç³» ---
pop_av = _present(POP_COLS, lf)
if pop_av:
    past_race_exprs.extend([
        pl.min_horizontal([pl.col(c) for c in pop_av]).alias("best_popularity_last3"),
        pl.mean_horizontal([pl.col(c) for c in pop_av]).alias("avg_popularity_last3"),
        pl.concat_list([pl.col(c) for c in pop_av]).list.eval(pl.element().std()).list.get(0).alias("std_popularity_last3"),
        pl.concat_list([pl.col(c) for c in pop_av]).list.eval(pl.element().var()).list.get(0).alias("var_popularity_last3"),
    ])
    if "last_popularity" in pop_av and "two_back_popularity" in pop_av:
        past_race_exprs.append((pl.col("two_back_popularity") - pl.col("last_popularity")).alias("pop_improve_L1_vs_L2"))

if past_race_exprs:
    lf = lf.with_columns(past_race_exprs)
    log(f"âœ… éå»èµ°æ´¾ç”Ÿç‰¹å¾´é‡ ({len(past_race_exprs)}åˆ—) ã‚’è¿½åŠ å®Œäº†")

# â”€â”€ â‘¨ æ—¥æœ¬èªåˆ—æ®‹å­˜ãƒã‚§ãƒƒã‚¯ ----------------------------------------------
from polars.datatypes import List as ListDtype
list_cols = [name for name, dtype in lf.schema.items() if isinstance(dtype, ListDtype)]
if list_cols:
    print("âš ï¸  List å‹ï¼ˆå¯å¤‰é•·ï¼‰ã®ã¾ã¾æ®‹ã£ã¦ã„ã‚‹åˆ—:", list_cols)
    lf = lf.drop(list_cols)

remain = [c for c in lf.schema if not re.fullmatch(r"[A-Za-z0-9_]+", c)]
if remain:
    raise RuntimeError(f"æœªè‹±èªåŒ–åˆ—ã‚ã‚Š â†’ {remain}")

# â”€â”€ â‘© Parquet æ›¸ãå‡ºã— ---------------------------------------------------
# =============================================================================
# ã‚¿ã‚¤ãƒˆãƒ«: Parquet æ›¸ãå‡ºã—ç›´å‰ã® dtype æœ€çµ‚å›ºå®šï¼ˆrace_code ã¯ Utf8ï¼‰
# èª¬æ˜: ç‰©ç†ã‚¹ã‚­ãƒ¼ãƒã‚’ string/large_string ã«å›ºå®šã•ã›ã‚‹ãŸã‚ã€collect ç›´å‰ã«å†ã‚­ãƒ£ã‚¹ãƒˆã€‚
# =============================================================================
if "race_code" in lf.columns:
    lf = lf.with_columns(pl.col("race_code").cast(pl.Utf8))

df_out = lf.collect(streaming=True)
log("æœ€çµ‚ collect å®Œäº†")
import pyarrow as pa
import pyarrow.parquet as pq
table = pa.Table.from_batches(df_out.to_arrow().to_batches())
pq.write_table(table, BASE_PARQUET, compression="zstd")
log("PyArrow çµŒç”±ã§ Parquet write å®Œäº†")
print(f"âœ… rows={df_out.height:,} | cols={len(df_out.columns)} â†’ {BASE_PARQUET}")

# â”€â”€ â‘ª ãƒãƒƒãƒ”ãƒ³ã‚°è¾æ›¸ä¿å­˜ --------------------------------------------------
Path(J2E_JSON).parent.mkdir(parents=True, exist_ok=True)
with open(J2E_JSON, "w", encoding="utf8") as f:
    json.dump(j2e, f, ensure_ascii=False, indent=2)
print(f"âœ… j2e.json ä¿å­˜ â†’ {J2E_JSON}")

# â”€â”€ â‘« ã€JRA05è¿½åŠ ã€‘ç›£æŸ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å‡ºåŠ› -------------------------------------
log("ç›£æŸ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆãƒ»ä¿å­˜")
Path(AUDIT_META_CSV).parent.mkdir(parents=True, exist_ok=True)
meta_data = []
for col_name in df_out.columns:
    col_series = df_out[col_name]
    meta_data.append({
        "column_name": col_name,
        "dtype": str(col_series.dtype),
        "n_unique": col_series.n_unique(),
        "null_count": col_series.null_count(),
        "null_ratio": col_series.null_count() / len(df_out) if len(df_out) > 0 else 0,
    })
meta_df = pl.DataFrame(meta_data)
meta_df.write_csv(AUDIT_META_CSV)
log(f"âœ… ç›£æŸ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ â†’ {AUDIT_META_CSV}")

